{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-20T16:30:47.517218Z",
     "start_time": "2025-04-20T16:30:47.041292Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:30:59.755183Z",
     "start_time": "2025-04-20T16:30:58.772020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_name = \"test_500\"\n",
    "final_dataset = load_dataset(f\"dbaeka/soen_691_{test_name}_meta_set\")['test']"
   ],
   "id": "c8199bcb8979a98",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:31:00.540329Z",
     "start_time": "2025-04-20T16:31:00.531741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_full = final_dataset.to_pandas()\n",
    "\n",
    "# Create BERT score bins\n",
    "quantiles = df_full[\"bert_score\"].quantile([0.33, 0.66])\n",
    "low_thresh, high_thresh = quantiles[0.33], quantiles[0.66]"
   ],
   "id": "d39654e1c47fdcf6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:31:02.926023Z",
     "start_time": "2025-04-20T16:31:02.923926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign_quality(score):\n",
    "    if score <= low_thresh:\n",
    "        return \"low\"\n",
    "    elif score <= high_thresh:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\""
   ],
   "id": "58e96303faf3e009",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:31:03.841030Z",
     "start_time": "2025-04-20T16:31:03.832287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_full[\"bert_quality\"] = df_full[\"bert_score\"].apply(assign_quality)\n",
    "df_full.head()"
   ],
   "id": "f7e2e33f37f7057a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               hash                                               gold  \\\n",
       "0  033b0baff52bb483  If there are no manifests, then entries should...   \n",
       "1  c1752542d5b833d3  Didn't went with backwards compatibility since...   \n",
       "2  7dc3d2474c83cca7            Is this actually a lint related change?   \n",
       "3  973d5f8f3c42730f  I don't know if there are strict conventions a...   \n",
       "4  9ef6bf7111827712           what to do if some failed? just logging?   \n",
       "\n",
       "                                                pred  \\\n",
       "0  The change gracefully handles the case where a...   \n",
       "1  The log message should include which collector...   \n",
       "2  The percent sign doesn't need to be escaped in...   \n",
       "3  The message doesn't explain why sys.exit() is ...   \n",
       "4  The error message should provide more context ...   \n",
       "\n",
       "                                                 cot  lang  \\\n",
       "0  This code change is addressing the case where ...  java   \n",
       "1  Let me analyze the code change:\\n\\n1. The meth...   .cs   \n",
       "2  In this code diff, a regex pattern is being mo...    js   \n",
       "3  I'm looking at a code review request for an ad...    py   \n",
       "4  The given code shows a change where a `CHECK_E...   cpp   \n",
       "\n",
       "                                             summary  bert_score  \\\n",
       "0            Collect all data files in the manifest.    0.849598   \n",
       "1  FailedToReachCollector - Method failed to reac...    0.830813   \n",
       "2  Creates all inputs of a block and removes all ...    0.855430   \n",
       "3  Uses the dict constructor a list of transient ...    0.840675   \n",
       "4  Clean expired hosts. expired hosts to offline ...    0.851026   \n",
       "\n",
       "                                               patch bert_quality  \n",
       "0  @@ -191,7 +191,10 @@ public class FindFiles {\\...       medium  \n",
       "1  @@ -26,11 +26,12 @@ namespace OpenTelemetry.Ex...          low  \n",
       "2  @@ -185,7 +185,7 @@ Blockly.ScratchBlocks.Proc...       medium  \n",
       "3  @@ -273,6 +273,11 @@ class RefactoringChecker(...          low  \n",
       "4  @@ -146,7 +146,9 @@ void ActiveHostsMan::clean...       medium  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>gold</th>\n",
       "      <th>pred</th>\n",
       "      <th>cot</th>\n",
       "      <th>lang</th>\n",
       "      <th>summary</th>\n",
       "      <th>bert_score</th>\n",
       "      <th>patch</th>\n",
       "      <th>bert_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>033b0baff52bb483</td>\n",
       "      <td>If there are no manifests, then entries should...</td>\n",
       "      <td>The change gracefully handles the case where a...</td>\n",
       "      <td>This code change is addressing the case where ...</td>\n",
       "      <td>java</td>\n",
       "      <td>Collect all data files in the manifest.</td>\n",
       "      <td>0.849598</td>\n",
       "      <td>@@ -191,7 +191,10 @@ public class FindFiles {\\...</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c1752542d5b833d3</td>\n",
       "      <td>Didn't went with backwards compatibility since...</td>\n",
       "      <td>The log message should include which collector...</td>\n",
       "      <td>Let me analyze the code change:\\n\\n1. The meth...</td>\n",
       "      <td>.cs</td>\n",
       "      <td>FailedToReachCollector - Method failed to reac...</td>\n",
       "      <td>0.830813</td>\n",
       "      <td>@@ -26,11 +26,12 @@ namespace OpenTelemetry.Ex...</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7dc3d2474c83cca7</td>\n",
       "      <td>Is this actually a lint related change?</td>\n",
       "      <td>The percent sign doesn't need to be escaped in...</td>\n",
       "      <td>In this code diff, a regex pattern is being mo...</td>\n",
       "      <td>js</td>\n",
       "      <td>Creates all inputs of a block and removes all ...</td>\n",
       "      <td>0.855430</td>\n",
       "      <td>@@ -185,7 +185,7 @@ Blockly.ScratchBlocks.Proc...</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>973d5f8f3c42730f</td>\n",
       "      <td>I don't know if there are strict conventions a...</td>\n",
       "      <td>The message doesn't explain why sys.exit() is ...</td>\n",
       "      <td>I'm looking at a code review request for an ad...</td>\n",
       "      <td>py</td>\n",
       "      <td>Uses the dict constructor a list of transient ...</td>\n",
       "      <td>0.840675</td>\n",
       "      <td>@@ -273,6 +273,11 @@ class RefactoringChecker(...</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9ef6bf7111827712</td>\n",
       "      <td>what to do if some failed? just logging?</td>\n",
       "      <td>The error message should provide more context ...</td>\n",
       "      <td>The given code shows a change where a `CHECK_E...</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Clean expired hosts. expired hosts to offline ...</td>\n",
       "      <td>0.851026</td>\n",
       "      <td>@@ -146,7 +146,9 @@ void ActiveHostsMan::clean...</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:31:09.397345Z",
     "start_time": "2025-04-20T16:31:09.392647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lang_counts = df_full[\"lang\"].value_counts()\n",
    "print(\"Language distribution in original dataset:\")\n",
    "print(lang_counts)"
   ],
   "id": "4b5c60dcd323b9cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language distribution in original dataset:\n",
      "lang\n",
      "go      126\n",
      "java     83\n",
      "py       69\n",
      "rb       49\n",
      "js       47\n",
      "cpp      41\n",
      ".cs      40\n",
      "php      24\n",
      "c        21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:31:10.901164Z",
     "start_time": "2025-04-20T16:31:10.897577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_EVALUATORS = 5\n",
    "NUM_OVERLAP_ITEMS = 60  # Items rated by ALL evaluators\n",
    "NUM_UNIQUE_ITEMS_PER_EVALUATOR = 48 # Items rated by only ONE evaluator\n",
    "SAMPLES_PER_EVALUATOR = NUM_OVERLAP_ITEMS + NUM_UNIQUE_ITEMS_PER_EVALUATOR # 108\n",
    "\n",
    "TOTAL_UNIQUE_ITEMS_FOR_UNIQUE_SETS = NUM_UNIQUE_ITEMS_PER_EVALUATOR * NUM_EVALUATORS # 48 * 5 = 240\n",
    "TOTAL_UNIQUE_ITEMS_NEEDED = NUM_OVERLAP_ITEMS + TOTAL_UNIQUE_ITEMS_FOR_UNIQUE_SETS # 60 + 240 = 300\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "LANGUAGES_TO_INCLUDE = [\"go\", \"java\", \"py\", \"js\", \"php\"]\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ],
   "id": "4a289439e4ac96d5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:31:12.117297Z",
     "start_time": "2025-04-20T16:31:12.113226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if LANGUAGES_TO_INCLUDE:\n",
    "    original_length = len(df_full)\n",
    "    df_full = df_full[df_full[\"lang\"].isin(LANGUAGES_TO_INCLUDE)]\n",
    "    print(f\"Filtered from {original_length} to {len(df_full)} samples based on selected languages.\")"
   ],
   "id": "e70269509c6b220d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 500 to 349 samples based on selected languages.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:31:15.873177Z",
     "start_time": "2025-04-20T16:31:15.868681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\nSampling {TOTAL_UNIQUE_ITEMS_NEEDED} unique items...\")\n",
    "# Define stratification columns (can adjust if bert_quality wasn't assigned)\n",
    "stratify_cols = ['lang']\n",
    "if 'bert_quality' in df_full.columns and df_full[\"bert_quality\"].nunique() > 1:\n",
    "     stratify_cols.append('bert_quality')\n",
    "     print(f\"Stratifying sample by: {stratify_cols}\")\n",
    "else:\n",
    "     print(f\"Stratifying sample by: {stratify_cols} ('bert_quality' not used for stratification)\")\n",
    "\n",
    "# Check if enough data available\n",
    "if len(df_full) < TOTAL_UNIQUE_ITEMS_NEEDED:\n",
    "    print(f\"Error: Not enough items in the filtered dataset ({len(df_full)}) to sample {TOTAL_UNIQUE_ITEMS_NEEDED} unique items.\")\n",
    "    exit()"
   ],
   "id": "48d10f22799f70d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 300 unique items...\n",
      "Stratifying sample by: ['lang', 'bert_quality']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:31:31.511947Z",
     "start_time": "2025-04-20T16:31:31.496649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Perform stratified sampling\n",
    "df_full['stratify_key'] = df_full[stratify_cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "# Calculate how many to sample from each group proportionally\n",
    "n_total = len(df_full)\n",
    "n_sample = TOTAL_UNIQUE_ITEMS_NEEDED\n",
    "sampled_indices = df_full.groupby('stratify_key', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=min(len(x), max(1, int(np.ceil(len(x) * n_sample / n_total)))), random_state=RANDOM_SEED)\n",
    ").index\n",
    "\n",
    "# Adjust sample size if proportional sampling didn't yield exactly n_sample\n",
    "current_sample_size = len(sampled_indices)\n",
    "if current_sample_size < n_sample:\n",
    "    print(f\"Adjusting sample size: needed {n_sample}, got {current_sample_size} proportionally.\")\n",
    "    remaining_indices = df_full.index.difference(sampled_indices)\n",
    "    additional_samples = np.random.choice(remaining_indices, n_sample - current_sample_size, replace=False)\n",
    "    sampled_indices = sampled_indices.union(pd.Index(additional_samples))\n",
    "elif current_sample_size > n_sample:\n",
    "     print(f\"Adjusting sample size: needed {n_sample}, got {current_sample_size} proportionally.\")\n",
    "     sampled_indices = np.random.choice(sampled_indices, n_sample, replace=False)\n",
    "\n",
    "\n",
    "df_sampled = df_full.loc[sampled_indices].copy()\n",
    "# Drop the temporary key\n",
    "df_sampled = df_sampled.drop(columns=['stratify_key'])\n",
    "df_full = df_full.drop(columns=['stratify_key']) # Drop from original too\n",
    "\n",
    "\n",
    "print(f\"Sampled {len(df_sampled)} unique items.\")"
   ],
   "id": "3737d9f9da6bade2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting sample size: needed 300, got 306 proportionally.\n",
      "Sampled 300 unique items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jx/xnp365p141d9_zvcrt4d5qvh0000gn/T/ipykernel_20735/3233782357.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_indices = df_full.groupby('stratify_key', group_keys=False).apply(\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:31:50.249086Z",
     "start_time": "2025-04-20T16:31:50.242552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"\\nSplitting sampled items into {NUM_OVERLAP_ITEMS} overlap and {TOTAL_UNIQUE_ITEMS_FOR_UNIQUE_SETS} unique items...\")\n",
    "\n",
    "# Use stratification for the split as well\n",
    "try:\n",
    "    # Ensure stratification column exists and has variability\n",
    "    stratify_col_split = 'lang' # Default to lang\n",
    "    if 'bert_quality' in df_sampled.columns and df_sampled['bert_quality'].nunique() > 1:\n",
    "        stratify_col_split = 'bert_quality' # Use quality if available\n",
    "\n",
    "    df_overlap, df_unique_pool = train_test_split(\n",
    "        df_sampled,\n",
    "        test_size=TOTAL_UNIQUE_ITEMS_FOR_UNIQUE_SETS, # Size of the unique pool\n",
    "        train_size=NUM_OVERLAP_ITEMS,            # Size of the overlap pool\n",
    "        random_state=RANDOM_SEED,\n",
    "        stratify=df_sampled[[stratify_col_split]] # Stratify the split\n",
    "    )\n",
    "    print(f\"Split complete: {len(df_overlap)} overlap items, {len(df_unique_pool)} unique pool items.\")\n",
    "except ValueError as e:\n",
    "     print(f\"Warning: Could not stratify split ({e}). Performing random split.\")\n",
    "     df_overlap = df_sampled.sample(n=NUM_OVERLAP_ITEMS, random_state=RANDOM_SEED)\n",
    "     df_unique_pool = df_sampled.drop(df_overlap.index)"
   ],
   "id": "a841616d234fd34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting sampled items into 60 overlap and 240 unique items...\n",
      "Split complete: 60 overlap items, 240 unique pool items.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:32:50.514663Z",
     "start_time": "2025-04-20T16:32:50.507016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nAssigning items to evaluators...\")\n",
    "evaluator_assignments = {i: [] for i in range(NUM_EVALUATORS)} \n",
    "\n",
    "overlap_items_list = df_overlap.to_dict('records')\n",
    "for item_data in overlap_items_list:\n",
    "    for i in range(NUM_EVALUATORS):\n",
    "        evaluator_assignments[i].append(item_data)\n",
    "print(f\"Assigned {len(df_overlap)} overlap items to all {NUM_EVALUATORS} evaluators.\")\n",
    "\n",
    "unique_items_list = df_unique_pool.to_dict('records')\n",
    "random.shuffle(unique_items_list)\n",
    "\n",
    "items_per_evaluator_unique = TOTAL_UNIQUE_ITEMS_FOR_UNIQUE_SETS // NUM_EVALUATORS\n",
    "if TOTAL_UNIQUE_ITEMS_FOR_UNIQUE_SETS % NUM_EVALUATORS != 0:\n",
    "     print(f\"Warning: Unique items ({TOTAL_UNIQUE_ITEMS_FOR_UNIQUE_SETS}) not perfectly divisible by evaluators ({NUM_EVALUATORS}). Distribution might be slightly uneven.\")\n",
    "\n",
    "start_idx = 0\n",
    "for i in range(NUM_EVALUATORS):\n",
    "    if i == NUM_EVALUATORS - 1:\n",
    "         end_idx = len(unique_items_list)\n",
    "    else:\n",
    "         end_idx = start_idx + items_per_evaluator_unique\n",
    "\n",
    "    unique_slice = unique_items_list[start_idx:end_idx]\n",
    "    evaluator_assignments[i].extend(unique_slice)\n",
    "    print(f\"Assigned {len(unique_slice)} unique items to evaluator {i+1}.\")\n",
    "    start_idx = end_idx"
   ],
   "id": "5ec57bf48140c901",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assigning items to evaluators...\n",
      "Assigned 60 overlap items to all 5 evaluators.\n",
      "Assigned 48 unique items to evaluator 1.\n",
      "Assigned 48 unique items to evaluator 2.\n",
      "Assigned 48 unique items to evaluator 3.\n",
      "Assigned 48 unique items to evaluator 4.\n",
      "Assigned 48 unique items to evaluator 5.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:35:04.003478Z",
     "start_time": "2025-04-20T16:35:03.977539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nVerifying final assignment counts...\")\n",
    "all_assigned_data = []\n",
    "for evaluator_id_zero_based, assigned_items in evaluator_assignments.items():\n",
    "    evaluator_id_one_based = evaluator_id_zero_based + 1\n",
    "    num_assigned = len(assigned_items)\n",
    "    print(f\"Evaluator {evaluator_id_one_based} has {num_assigned} items assigned.\")\n",
    "    if num_assigned != SAMPLES_PER_EVALUATOR:\n",
    "        print(f\"  WARNING: Evaluator {evaluator_id_one_based} has {num_assigned} items, expected {SAMPLES_PER_EVALUATOR}.\")\n",
    "\n",
    "    for item_dict in assigned_items:\n",
    "        item_dict_copy = item_dict.copy()\n",
    "        item_dict_copy['evaluator_id'] = evaluator_id_one_based\n",
    "        all_assigned_data.append(item_dict_copy)\n",
    "\n",
    "df_final_assignments = pd.DataFrame(all_assigned_data)\n",
    "\n",
    "# Optional: Shuffle the final combined list so items aren't grouped by overlap/unique status\n",
    "df_final_assignments = df_final_assignments.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTotal assignments generated: {len(df_final_assignments)}\")\n",
    "\n",
    "df_final_assignments.to_csv(\"combined_evaluator_assignments.csv\")\n",
    "print(f\"Combined assignments saved to: combined_evaluator_assignments\")\n",
    "\n",
    "print(\"\\nSample of final assignment data:\")\n",
    "df_final_assignments.head()"
   ],
   "id": "66def9747b3aa2ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying final assignment counts...\n",
      "Evaluator 1 has 108 items assigned.\n",
      "Evaluator 2 has 108 items assigned.\n",
      "Evaluator 3 has 108 items assigned.\n",
      "Evaluator 4 has 108 items assigned.\n",
      "Evaluator 5 has 108 items assigned.\n",
      "\n",
      "Total assignments generated: 540\n",
      "Combined assignments saved to: combined_evaluator_assignments\n",
      "\n",
      "Sample of final assignment data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               hash                                               gold  \\\n",
       "0  c0782327891b2a05  All the code that reference to this function m...   \n",
       "1  f250d880ef09208a  Ideally, we'd fold the schema into an expanded...   \n",
       "2  4dbb6143e70527de  @kevinansfield Would be cool if you can take a...   \n",
       "3  72736b53cb9c9ae6  And again. The reason it's bad is that if some...   \n",
       "4  e4f230a58d1c5806  It's very error-prone to have so large `try` c...   \n",
       "\n",
       "                                                pred  \\\n",
       "0  The method name change better reflects its pur...   \n",
       "1  The content may exceed Elasticsearch's maximum...   \n",
       "2  Is 'member-subscription' a custom transform, a...   \n",
       "3  Avoid using Sun's proprietary API as they're n...   \n",
       "4  The variable `returned_results` was removed bu...   \n",
       "\n",
       "                                                 cot lang  \\\n",
       "0  I need to provide a formal code review for the...   go   \n",
       "1  Let me analyze the code change:\\n\\n1. The orig...   py   \n",
       "2  I need to give a formal code review for this d...   js   \n",
       "3  I'm reviewing a diff that shows an added impor...   js   \n",
       "4  This code fixes an exception handling block. P...   py   \n",
       "\n",
       "                                             summary  bert_score  \\\n",
       "0  validateOptions validates the options for the ...    0.846068   \n",
       "1                   get the byte contents of a file.    0.864433   \n",
       "2                       Default Model extend method.    0.841333   \n",
       "3  Reads a single non - null   from the System. T...    0.856422   \n",
       "4  Post process a DataFrame with a set of logical...    0.837403   \n",
       "\n",
       "                                               patch bert_quality  \\\n",
       "0  @@ -68,8 +68,8 @@ func (c *cstorSnapshotComman...       medium   \n",
       "1  @@ -87,7 +87,8 @@ def get_contents(bucket, key...         high   \n",
       "2  @@ -4,5 +4,6 @@ import attr from 'ember-data/a...          low   \n",
       "3  @@ -19,6 +19,8 @@ package org.openqa.grid.web;...       medium   \n",
       "4  @@ -81,10 +81,10 @@ def file_list_to_folder(df...          low   \n",
       "\n",
       "   evaluator_id  \n",
       "0             1  \n",
       "1             4  \n",
       "2             5  \n",
       "3             3  \n",
       "4             2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>gold</th>\n",
       "      <th>pred</th>\n",
       "      <th>cot</th>\n",
       "      <th>lang</th>\n",
       "      <th>summary</th>\n",
       "      <th>bert_score</th>\n",
       "      <th>patch</th>\n",
       "      <th>bert_quality</th>\n",
       "      <th>evaluator_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0782327891b2a05</td>\n",
       "      <td>All the code that reference to this function m...</td>\n",
       "      <td>The method name change better reflects its pur...</td>\n",
       "      <td>I need to provide a formal code review for the...</td>\n",
       "      <td>go</td>\n",
       "      <td>validateOptions validates the options for the ...</td>\n",
       "      <td>0.846068</td>\n",
       "      <td>@@ -68,8 +68,8 @@ func (c *cstorSnapshotComman...</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f250d880ef09208a</td>\n",
       "      <td>Ideally, we'd fold the schema into an expanded...</td>\n",
       "      <td>The content may exceed Elasticsearch's maximum...</td>\n",
       "      <td>Let me analyze the code change:\\n\\n1. The orig...</td>\n",
       "      <td>py</td>\n",
       "      <td>get the byte contents of a file.</td>\n",
       "      <td>0.864433</td>\n",
       "      <td>@@ -87,7 +87,8 @@ def get_contents(bucket, key...</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4dbb6143e70527de</td>\n",
       "      <td>@kevinansfield Would be cool if you can take a...</td>\n",
       "      <td>Is 'member-subscription' a custom transform, a...</td>\n",
       "      <td>I need to give a formal code review for this d...</td>\n",
       "      <td>js</td>\n",
       "      <td>Default Model extend method.</td>\n",
       "      <td>0.841333</td>\n",
       "      <td>@@ -4,5 +4,6 @@ import attr from 'ember-data/a...</td>\n",
       "      <td>low</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72736b53cb9c9ae6</td>\n",
       "      <td>And again. The reason it's bad is that if some...</td>\n",
       "      <td>Avoid using Sun's proprietary API as they're n...</td>\n",
       "      <td>I'm reviewing a diff that shows an added impor...</td>\n",
       "      <td>js</td>\n",
       "      <td>Reads a single non - null   from the System. T...</td>\n",
       "      <td>0.856422</td>\n",
       "      <td>@@ -19,6 +19,8 @@ package org.openqa.grid.web;...</td>\n",
       "      <td>medium</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e4f230a58d1c5806</td>\n",
       "      <td>It's very error-prone to have so large `try` c...</td>\n",
       "      <td>The variable `returned_results` was removed bu...</td>\n",
       "      <td>This code fixes an exception handling block. P...</td>\n",
       "      <td>py</td>\n",
       "      <td>Post process a DataFrame with a set of logical...</td>\n",
       "      <td>0.837403</td>\n",
       "      <td>@@ -81,10 +81,10 @@ def file_list_to_folder(df...</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af022ff84c7f9707"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
